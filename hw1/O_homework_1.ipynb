{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Other activation functions (20%)\n",
    "### The leaky Relu is defined as $max(0.1x, x)$. \n",
    " - What is its derivative? (Please express in \"easy\" format\")\n",
    " - Is it suitable for back propagation?\n",
    " \n",
    "### $tanh$ is defined as  $\\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$. \n",
    " - What is its derivative? (Please express in \"easy\" format\")\n",
    " - Is it suitable for back propagation?\n",
    " - How is it different from the sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add answers in plain text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Linear regression in Keras (40%)\n",
    "\n",
    "#### We'd like to use keras to perform linear regression and compare it to another tool (scikit-learn)\n",
    "#### We'll compare OLS, ridge ($L2$ regularization) and LASSO ($L1$ regularization) using both keras and scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# many of these imports to be removed\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Softmax, Dropout\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "np.random.seed(1024)\n",
    "num_observations = 1024\n",
    "coefs = np.array([-1.2, 5, 0, .22, 2, 0, 4])  # notice, there are zeros!\n",
    "noise_amplitude = .05\n",
    "\n",
    "num_variables = coefs.shape[0]\n",
    "\n",
    "x = np.random.rand(num_observations, num_variables)\n",
    "y = np.dot(x, coefs) + noise_amplitude * np.random.rand(num_observations)\n",
    "\n",
    "cutoff = int(.8 * num_observations)\n",
    "x_train, x_test = x[:cutoff], x[cutoff:]\n",
    "y_train, y_test = y[:cutoff], y[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((819, 7), (819,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# insert code to make predictions here\n",
    "# ...\n",
    "# lin_reg_predictions = ...\n",
    "mean_squared_error(y_test, lin_reg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that the coefficients are all close the the \"real\" ones used to generate the data\n",
    "# lin_reg_coefs = ...\n",
    "pd.Series(lin_reg_coefs, name='fit coefficients').to_frame().join(pd.Series(coefs, name='real coefficients')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def plot_model_in_notebook(model):\n",
    "    return SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use keras to solve the same problem \n",
    "K.clear_session()\n",
    "#input_data = Input(shape=FIXME)\n",
    "# add model definition here\n",
    "# keras_lin_reg = ...\n",
    "# don't forget to compile your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_model_in_notebook(keras_lin_reg)  # to be removed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many parameters does the model have? \n",
    "### Explicitly show the calculation, explain it, and verify that it agrees with `model.count_params()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras_lin_reg.fit( ... ) \n",
    "# mean_squared_error(... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras ols coefficients</th>\n",
       "      <th>real coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.202948</td>\n",
       "      <td>-1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.004425</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004936</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219746</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.001384</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.998092</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keras ols coefficients  real coefficients\n",
       "0               -1.202948              -1.20\n",
       "1                5.004425               5.00\n",
       "2               -0.004936               0.00\n",
       "3                0.219746               0.22\n",
       "4                2.001384               2.00\n",
       "5               -0.000178               0.00\n",
       "6                3.998092               4.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the coefficients\n",
    "# keras_ols_coefs = ...\n",
    "\n",
    "pd.Series(keras_ols_coefs, name='keras ols coefficients').to_frame().join(pd.Series(coefs, name='real coefficients'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will add some regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1_l2\n",
    "regularizer = l1_l2(l1=0, l2=.1)\n",
    " # Dense(...) -> Dense(..., kernel_regularizer=regularizer)\n",
    "    \n",
    "# input_data = ...\n",
    "# keras_ridge_model = ...\n",
    "# don't forget to compile the model\n",
    "plot_model_in_notebook(keras_ridge_model)  # to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_ridge_model.fit(...\n",
    "# mean_squared_error(y_test, keras_ridge_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras_ridge_coefs = ...\n",
    "#pd.Series(keras_ridge_coefs, name='keras ridge coefficients').to_frame().join(pd.Series(coefs, name='real coefficients'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge regression in sklaern\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Add code here\n",
    "# sklearn_ridge_coef = ...\n",
    "#pd.Series(sklearn_ridge_coef, name='ridge coefficients').to_frame().join(pd.Series(coefs, name='real coefficients'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare coefficients from various methods\n",
    "pd.concat([\n",
    "    pd.Series(sklearn_ridge_coef, name='ridge coefs'),\n",
    "    pd.Series(keras_ridge_coefs, name='keras L2 coefs'),\n",
    "    pd.Series(coefs, name='real coefs')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In fact, given the zero coefficients, LASSO might have been a better model. \n",
    "## LASSO uses $L_{1}$ regularization which will make sparse coefficients (some are zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso coefficients</th>\n",
       "      <th>real coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.048288</td>\n",
       "      <td>-1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.815515</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.746026</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.731789</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lasso coefficients  real coefficients\n",
       "0           -0.048288              -1.20\n",
       "1            3.815515               5.00\n",
       "2            0.000000               0.00\n",
       "3            0.000000               0.22\n",
       "4            0.746026               2.00\n",
       "5           -0.000000               0.00\n",
       "6            2.731789               4.00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Add code here\n",
    "# sklearn_lasso_coefs = \n",
    "pd.Series(sklearn_lasso_coefs, name='lasso coefficients').to_frame().join(pd.Series(coefs, name='real coefficients'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do lasso with keras\n",
    "\n",
    "#keras_lasso_model = ...\n",
    "# don't forget to compile the model\n",
    "plot_model_in_notebook(keras_lasso_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_lasso_model.fit(...\n",
    "# keras_lasso_coefs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all the coefficients\n",
    "pd.concat([\n",
    "    pd.Series(sklearn_ridge_coefs, name='ridge coefs'),\n",
    "    pd.Series(keras_ridge_coefs, name='keras L2 coefs'),\n",
    "    pd.Series(sklearn_lasso_coefs, name='lasso coefs'),\n",
    "    pd.Series(keras_lasso_coefs, name='keras L1 coefs'),\n",
    "    pd.Series(lin_reg.coef_, name='ols coefs'),\n",
    "    pd.Series(coefs, name='real coefs'),\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(find optimal regularization paramter) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Keras for harder mnist problems (40%)\n",
    "#### The deep net during lecture has a hard time distiguishing between 9 and 4.\n",
    "#### We will build an algorithm to do this binary classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe to restart here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "\n",
    "# many of these to be removed\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Softmax, Dropout\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9457, 784)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def preprocess_training_data(data):\n",
    "    data = data.reshape(data.shape[0], data.shape[1] * data.shape[2])\n",
    "    data = data.astype('float32') / 255\n",
    "    return data\n",
    "\n",
    "def preprocess_targets(target, num_classes):\n",
    "    return to_categorical(target, num_classes)\n",
    "\n",
    "\n",
    "def subset_to_9_and_4(x, y):  # this is a new function\n",
    "    mask = (y == 9) | (y == 4)\n",
    "    new_x = x[mask]\n",
    "    new_y = (y[mask] == 4).astype('int64')\n",
    "    return new_x, new_y\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = preprocess_training_data(x_train)\n",
    "x_test = preprocess_training_data(x_test)\n",
    "\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "\n",
    "y_train_ohe = preprocess_targets(y_train, num_classes)\n",
    "y_test_ohe = preprocess_targets(y_test, num_classes)\n",
    "\n",
    "train_frac = 0.8\n",
    "cutoff = int(x_train.shape[0] * train_frac)\n",
    "x_train, x_val = x_train[:cutoff], x_train[cutoff:]\n",
    "y_train, y_val = y_train[:cutoff], y_train[cutoff:]\n",
    "y_train_ohe, y_val_ohe = y_train_ohe[:cutoff], y_train_ohe[cutoff:]\n",
    "\n",
    "x_train, y_train = subset_to_9_and_4(x_train, y_train)\n",
    "x_val, y_val = subset_to_9_and_4(x_val, y_val)\n",
    "x_test, y_test = subset_to_9_and_4(x_test, y_test)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Add code here\n",
    "\n",
    "# sklearn_lr_predictions = ...\n",
    "accuracy_score(y_test, sklearn_lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def plot_model_in_notebook(model):\n",
    "    return SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "num_hidden_units = 256\n",
    "# digit_input = ...\n",
    "# define model\n",
    "# model = ...\n",
    "\n",
    "#NB: you probably want BINARY cross entropy i.e. 'binary_crossentropy' for the loss function\n",
    "# model.compile(..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_in_notebook(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many params does the model have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code here\n",
    "# model.fit(...\n",
    "\n",
    "# keras_predictions = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "accuracy_score(y_test, keras_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE! Congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
