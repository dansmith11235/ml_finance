{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: counting parameters (30%):\n",
    "## Count the parameters for the following three network configurations. \n",
    "## Please show & clearly explain how you arrive at the numbers (not just use count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 512\n",
    "MAX_WORDS = 50000\n",
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network 1\n",
    "word_input = Input(\n",
    "    shape=(MAX_SEQ_LEN,), \n",
    "    dtype='int32'\n",
    ")\n",
    "hidden_state = Embedding(\n",
    "    MAX_WORDS, \n",
    "    EMBEDDING_DIM, \n",
    "    input_length=MAX_SEQ_LEN\n",
    ")(word_input)\n",
    "hidden_state = LSTM(\n",
    "    64, dropout=0.2)(hidden_state)\n",
    "hidden_state = Dense(32)(hidden_state)\n",
    "hidden_state = Dropout(0.2)(hidden_state)\n",
    "output = Dense(10, activation='softmax')(hidden_state)\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network 2\n",
    "word_input = Input(\n",
    "    shape=(MAX_SEQ_LEN,), \n",
    "    dtype='int32'\n",
    ")\n",
    "hidden_state = Embedding(\n",
    "    MAX_WORDS, \n",
    "    EMBEDDING_DIM, \n",
    "    input_length=MAX_SEQ_LEN\n",
    ")(word_input)\n",
    "\n",
    "hidden_state = SimpleRNN(\n",
    "    64, \n",
    "    return_sequences=True\n",
    ")(hidden_state)\n",
    "\n",
    "hidden_state = LSTM(\n",
    "    64, \n",
    "    recurrent_dropout=0.2\n",
    ")(hidden_state)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(hidden_state)\n",
    "model = Model(word_input, output)\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network 3\n",
    "word_input = Input(\n",
    "    shape=(MAX_SEQ_LEN,), \n",
    "    dtype='int32'\n",
    ")\n",
    "hidden_state = Embedding(\n",
    "    MAX_WORDS, \n",
    "    EMBEDDING_DIM, \n",
    "    input_length=MAX_SEQ_LEN\n",
    ")(word_input)\n",
    "\n",
    "hidden_state = LSTM(\n",
    "    64, \n",
    "    return_sequences=True\n",
    ")(hidden_state)\n",
    "\n",
    "hidden_state = LSTM(\n",
    "    64, \n",
    "    return_sequences=True\n",
    ")(hidden_state)\n",
    "\n",
    "\n",
    "hidden_state = Bidirectional(LSTM(\n",
    "    64, \n",
    "    recurrent_dropout=0.2\n",
    "))(hidden_state)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(hidden_state)\n",
    "\n",
    "model = Model(word_input, output)\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Many Ways to Solve the Same Problem (35%)\n",
    "### ... and the limits of deep learning...\n",
    "\n",
    "## We saw three ways to solve the IMDB problem:\n",
    " - flatten the sequence and send to a dense network\n",
    " - a (bidirectional) LSTM to get sequence information\n",
    " - being \"clever\" with the features we use (FastText)\n",
    " \n",
    "\n",
    "# We want to try to combine these \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "\n",
    "np.random.seed(\n",
    "    abs(hash('mit') // (2 ** 32 -1))\n",
    ")\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import (\n",
    "    SimpleRNN, Dense, LSTM,\n",
    "    Embedding, Input, Dropout,\n",
    "    Concatenate\n",
    ")\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_FROM = 3   # word index offset\n",
    "MAX_WORDS = 50000\n",
    "MAX_SEQ_LEN = 500\n",
    "EMBEDDING_DIM = 50\n",
    "NUM_HIDDEN_RNN = 64\n",
    "\n",
    "\n",
    "((int_sequences_train, y_train), \n",
    " (int_sequences_test, y_test)) = imdb.load_data(\n",
    "    num_words=MAX_WORDS, \n",
    "    index_from=INDEX_FROM\n",
    ")\n",
    "\n",
    "# Some word magic\n",
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v + INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "((int_sequences_train, y_train), \n",
    " (int_sequences_test, y_test)) = imdb.load_data(\n",
    "    num_words=MAX_WORDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = ''  # FIXME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_file(filepath):\n",
    "    word_to_vector = {}\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_to_vector[word] = vector\n",
    "    return word_to_vector\n",
    "\n",
    "word_vecs = load_glove_file(GLOVE_FILE)\n",
    "\n",
    "embedding_matrix = np.zeros((MAX_WORDS, EMBEDDING_DIM))\n",
    "for  i, word in id_to_word.items():\n",
    "    if i >= MAX_WORDS:\n",
    "        continue\n",
    "    embedding_vector = word_vecs.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Solve the problem with the \"Fasttext\" method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "\n",
    "def add_ngram(sequences, token_indices, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for ngram_value in range(2, ngram_range + 1):\n",
    "            for i in range(len(new_list) - ngram_value + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indices:\n",
    "                    new_list.append(token_indices[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_RANGE = 2\n",
    "MAX_WORDS_FT = 5000\n",
    "\n",
    "ft_sequences_train = int_sequences_train[:]  # makes a copy\n",
    "ft_sequences_test = int_sequences_test[:]  # makes a copy\n",
    "\n",
    "# TODO(filter ft_sequences to only elements that are less than MAX_WORDS_FT)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "if NGRAM_RANGE > 1:\n",
    "    # Create set of unique n-gram from the training set.\n",
    "    ngram_set = set()\n",
    "    for input_list in ft_sequences_train:\n",
    "        for i in range(2, NGRAM_RANGE + 1):\n",
    "            set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "            ngram_set.update(set_of_ngram)\n",
    "\n",
    "    # Dictionary mapping n-gram token to a unique integer.\n",
    "    # Integer values are greater than max_features in order\n",
    "    # to avoid collision with existing features.\n",
    "    start_index = MAX_WORDS_FT + 1\n",
    "    token_indices = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "    indices_token = {token_indices[k]: k for k in token_indices}\n",
    "\n",
    "    # max_features is the highest integer that could be found in the dataset.\n",
    "    MAX_FEATURES_FASTTEXT = np.max(list(indices_token.keys())) + 1\n",
    "\n",
    "    # Augmenting x_train and x_test with n-grams features\n",
    "    ft_sequences_train = add_ngram(ft_sequences_train, token_indices, NGRAM_RANGE)\n",
    "    ft_sequences_test = add_ngram(ft_sequences_test, token_indices, NGRAM_RANGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pad the sequences\n",
    "# YOUR CODE HERE\n",
    "#ft_sequences_train ... \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Constant\n",
    "from keras.layers import Flatten, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "fastext_word_input = Input(\n",
    "    shape=(MAX_SEQ_LEN,),\n",
    "    dtype='int32'\n",
    ")\n",
    "# your code here, don't forget to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~40s epoch\n",
    "model.fit(\n",
    "    ft_sequences_train,\n",
    "    y_train, \n",
    "    epochs=8, \n",
    "    batch_size=128, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pd.DataFrame(model.history.history)[['acc', 'val_acc']].plot(\n",
    "    figsize=(16,9), fontsize=16, style='o', markersize=16\n",
    ")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('epoch', fontsize=16)\n",
    "\n",
    "\n",
    "preds_ft = model.predict(ft_sequences_test).squeeze()\n",
    "test_acc_ft = accuracy_score(y_test, (preds_ft > 0.5).astype(int))\n",
    "plt.title('test accuracy = {:.3f}'.format(test_acc_ft), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Solve the problem with an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 50)           2500000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,529,505\n",
      "Trainable params: 29,505\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "single_word_input = Input(shape=(MAX_SEQ_LEN,), \n",
    "                   dtype='int32')\n",
    "\n",
    "# TODO: \n",
    "# make a non-trainable embedding\n",
    "# make a single layer lstm\n",
    "# make a single neuron dense layer\n",
    "\n",
    "# your code here\n",
    "# don't forget to compile the model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~60s / epoch\n",
    "model.fit(\n",
    "    int_sequences_train,\n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=128, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.history)[['acc', 'val_acc']].plot(\n",
    "    figsize=(16,9), fontsize=16, style='o', markersize=16\n",
    ")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('epoch', fontsize=16)\n",
    "\n",
    "\n",
    "preds_rnn = model.predict(int_sequences_test).squeeze()\n",
    "test_acc_rnn = accuracy_score(y_test, (preds_rnn > 0.5).astype(int))\n",
    "plt.title('test accuracy = {:.3f}'.format(test_acc_rnn), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Solve the problem by flattening the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 500, 50)           2500000   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                800032    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,300,065\n",
      "Trainable params: 800,065\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "single_word_input = Input(shape=(MAX_SEQ_LEN,), \n",
    "                   dtype='int32')\n",
    "\n",
    "# TODO\n",
    "# make a non-trainable embedding\n",
    "# flatten the sequence\n",
    "# add some dorpout\n",
    "# add a dense layer\n",
    "# add dropout\n",
    "# add a dense layer with one neuron\n",
    "\n",
    "# your code here\n",
    "# don't forget to compile the model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    int_sequences_train,\n",
    "    y_train, \n",
    "    epochs=8, \n",
    "    batch_size=128, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.history)[['acc', 'val_acc']].plot(\n",
    "    figsize=(16,9), fontsize=16, style='o', markersize=16\n",
    ")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('epoch', fontsize=16)\n",
    "\n",
    "\n",
    "preds_flat = model.predict(int_sequences_test).squeeze()\n",
    "test_acc_flat = accuracy_score(y_test, (preds_flat > 0.5).astype(int))\n",
    "plt.title('test accuracy = {:.3f}'.format(test_acc_flat), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Bagging\n",
    "## Improving with bagging\n",
    "In ML there is a common technique to __bag__ multiple estimators togther. \n",
    "\n",
    "The basic idea is to reduce variance by average together multiple estimators that should have\n",
    "different kinds of errors. \n",
    "\n",
    "NB: A random forest is a bagging estimator\n",
    "\n",
    "### Learning weights\n",
    " - We can learn weights for the various estimators (we have enough data to do this).\n",
    " - We'll do it on the test data, which is technically cheating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new accuracy 0.892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# TODO\n",
    "# - concatenate the test-set predictions from each method\n",
    "#      it should be a lenght-of-test-data x 3 vector\n",
    "# - fit a 3-feature logistic regression to the data\n",
    "# - print the test_set accuacy\n",
    "\n",
    "# your code here...\n",
    "\n",
    "# lr = LogisticRegression( ...\n",
    "\n",
    "# your code here...\n",
    "\n",
    "print('new accuracy {:.3f}'.format(accuracy_score(y_test, new_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the coefficients\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also just guess hard_coded weights based on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_flat = 1\n",
    "wt_rnn = 2\n",
    "wt_ft = 12\n",
    "\n",
    "total_wt = (wt_flat + wt_ft + wt_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 0.8850\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# - make a weighted average of all the predictions\n",
    "# - calculate the test accuracy\n",
    "\n",
    "# your code here\n",
    "\n",
    "print('test accuracy = {:.4f}'.format(test_acc_voted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: combine them with neural nets\n",
    "## Our goal is to construct a a neural network with two inputs and one output:\n",
    "### Inputs\n",
    " - Embedded glove words, untrainable, for the RNN and the flattening\n",
    " - The fastext bigrams\n",
    "### Output:\n",
    " - the usual `0/1` for the IMDB task\n",
    " \n",
    "### Newtork: \n",
    " - make a single LSTM on the word vectors\n",
    " - flatten the ORIGINAL word-vector sequence and have it go through a single dense layer\n",
    "    - add dropout appropriately\n",
    " - average the fasttext input over all the words\n",
    "\n",
    "This will make 3 different sets of features. You should\n",
    " - concatenate them\n",
    " - add some dropout\n",
    " - send the merged output to a single-neuron dense layer.\n",
    " \n",
    "# $ \\\\ $\n",
    "# Network\n",
    "```\n",
    "int-input-sequence   fastext-input sequence\n",
    "     |                      |\n",
    " embedding                embedding\n",
    " (non-trainable)          (trainabile)\n",
    " |                           |\n",
    " |\\                          |    \n",
    " | \\                         |\n",
    " |  \\                  Average over words\n",
    " |   \\                       |\n",
    " |    \\                      |\n",
    " |     \\                     |\n",
    " Flatt  LSTM                 |\n",
    " |        |                  |\n",
    " Drop     |                 /\n",
    " |        |                /\n",
    " Dense    |               /\n",
    " |         \\             /\n",
    " Drop       \\           /\n",
    " |           \\         /\n",
    " ######################\n",
    " ####### concat #######\n",
    " ######################\n",
    "          |\n",
    "         Drop\n",
    "          |\n",
    "        Dense(1)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# Your code here\n",
    "# don't forget to compile your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"719pt\" viewBox=\"0.00 0.00 904.50 719.00\" width=\"905pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-715 900.5,-715 900.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140578708520912 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140578708520912</title>\n",
       "<polygon fill=\"none\" points=\"143,-664.5 143,-710.5 406,-710.5 406,-664.5 143,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-683.8\">input_2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"268,-664.5 268,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"268,-687.5 323,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"323,-664.5 323,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364.5\" y=\"-695.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"323,-687.5 406,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364.5\" y=\"-672.3\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 140578676748528 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140578676748528</title>\n",
       "<polygon fill=\"none\" points=\"114.5,-581.5 114.5,-627.5 434.5,-627.5 434.5,-581.5 114.5,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-600.8\">embedding_2: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"275.5,-581.5 275.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"275.5,-604.5 330.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"330.5,-581.5 330.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382.5\" y=\"-612.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"330.5,-604.5 434.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382.5\" y=\"-589.3\">(None, 500, 50)</text>\n",
       "</g>\n",
       "<!-- 140578708520912&#45;&gt;140578676748528 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140578708520912-&gt;140578676748528</title>\n",
       "<path d=\"M274.5,-664.3799C274.5,-656.1745 274.5,-646.7679 274.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"278.0001,-637.784 274.5,-627.784 271.0001,-637.784 278.0001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676752168 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140578676752168</title>\n",
       "<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 269,-544.5 269,-498.5 0,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-517.8\">flatten_1: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"110,-498.5 110,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"110,-521.5 165,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"165,-498.5 165,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-529.3\">(None, 500, 50)</text>\n",
       "<polyline fill=\"none\" points=\"165,-521.5 269,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217\" y=\"-506.3\">(None, 25000)</text>\n",
       "</g>\n",
       "<!-- 140578676748528&#45;&gt;140578676752168 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140578676748528-&gt;140578676752168</title>\n",
       "<path d=\"M235.5022,-581.3799C219.1044,-571.6583 199.8623,-560.2505 182.5971,-550.0147\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"184.1611,-546.8731 173.7742,-544.784 180.5912,-552.8944 184.1611,-546.8731\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676749704 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140578676749704</title>\n",
       "<polygon fill=\"none\" points=\"287,-498.5 287,-544.5 544,-544.5 544,-498.5 287,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336\" y=\"-517.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"385,-498.5 385,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"385,-521.5 440,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"412.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"440,-498.5 440,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492\" y=\"-529.3\">(None, 500, 50)</text>\n",
       "<polyline fill=\"none\" points=\"440,-521.5 544,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492\" y=\"-506.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 140578676748528&#45;&gt;140578676749704 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140578676748528-&gt;140578676749704</title>\n",
       "<path d=\"M313.7764,-581.3799C330.2913,-571.6583 349.6708,-560.2505 367.0594,-550.0147\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"369.103,-552.8731 375.9452,-544.784 365.5519,-546.8407 369.103,-552.8731\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676586872 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140578676586872</title>\n",
       "<polygon fill=\"none\" points=\"53.5,-415.5 53.5,-461.5 329.5,-461.5 329.5,-415.5 53.5,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116\" y=\"-434.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"178.5,-415.5 178.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"178.5,-438.5 233.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"233.5,-415.5 233.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-446.3\">(None, 25000)</text>\n",
       "<polyline fill=\"none\" points=\"233.5,-438.5 329.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-423.3\">(None, 25000)</text>\n",
       "</g>\n",
       "<!-- 140578676752168&#45;&gt;140578676586872 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140578676752168-&gt;140578676586872</title>\n",
       "<path d=\"M150.3777,-498.3799C156.3802,-489.6394 163.3188,-479.5358 169.7669,-470.1465\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"172.7338,-472.0087 175.5098,-461.784 166.9635,-468.0459 172.7338,-472.0087\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140579245532160 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140579245532160</title>\n",
       "<polygon fill=\"none\" points=\"70,-332.5 70,-378.5 323,-378.5 323,-332.5 70,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121\" y=\"-351.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"172,-332.5 172,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"172,-355.5 227,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"227,-332.5 227,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-363.3\">(None, 25000)</text>\n",
       "<polyline fill=\"none\" points=\"227,-355.5 323,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-340.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140578676586872&#45;&gt;140579245532160 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140578676586872-&gt;140579245532160</title>\n",
       "<path d=\"M192.8928,-415.3799C193.3871,-407.1745 193.9537,-397.7679 194.4892,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"197.9896,-388.9764 195.0973,-378.784 191.0023,-388.5554 197.9896,-388.9764\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578708518672 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140578708518672</title>\n",
       "<polygon fill=\"none\" points=\"524,-415.5 524,-461.5 787,-461.5 787,-415.5 524,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"586.5\" y=\"-434.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"649,-415.5 649,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"676.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"649,-438.5 704,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"676.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"704,-415.5 704,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"745.5\" y=\"-446.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"704,-438.5 787,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"745.5\" y=\"-423.3\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 140578660586496 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140578660586496</title>\n",
       "<polygon fill=\"none\" points=\"495.5,-332.5 495.5,-378.5 815.5,-378.5 815.5,-332.5 495.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576\" y=\"-351.8\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"656.5,-332.5 656.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"684\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"656.5,-355.5 711.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"684\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"711.5,-332.5 711.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"763.5\" y=\"-363.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"711.5,-355.5 815.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"763.5\" y=\"-340.3\">(None, 500, 50)</text>\n",
       "</g>\n",
       "<!-- 140578708518672&#45;&gt;140578660586496 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140578708518672-&gt;140578660586496</title>\n",
       "<path d=\"M655.5,-415.3799C655.5,-407.1745 655.5,-397.7679 655.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"659.0001,-388.784 655.5,-378.784 652.0001,-388.784 659.0001,-388.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676586984 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140578676586984</title>\n",
       "<polygon fill=\"none\" points=\"85.5,-249.5 85.5,-295.5 341.5,-295.5 341.5,-249.5 85.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148\" y=\"-268.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-249.5 210.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-272.5 265.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-249.5 265.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-280.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-272.5 341.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-257.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140579245532160&#45;&gt;140578676586984 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140579245532160-&gt;140578676586984</title>\n",
       "<path d=\"M201.2354,-332.3799C202.9343,-324.0854 204.8846,-314.5633 206.7227,-305.5889\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"210.1532,-306.2829 208.731,-295.784 203.2956,-304.8783 210.1532,-306.2829\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676749368 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140578676749368</title>\n",
       "<polygon fill=\"none\" points=\"414.5,-249.5 414.5,-295.5 896.5,-295.5 896.5,-249.5 414.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576\" y=\"-268.8\">global_average_pooling1d_1: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"737.5,-249.5 737.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"765\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"737.5,-272.5 792.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"765\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"792.5,-249.5 792.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844.5\" y=\"-280.3\">(None, 500, 50)</text>\n",
       "<polyline fill=\"none\" points=\"792.5,-272.5 896.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844.5\" y=\"-257.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 140578660586496&#45;&gt;140578676749368 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140578660586496-&gt;140578676749368</title>\n",
       "<path d=\"M655.5,-332.3799C655.5,-324.1745 655.5,-314.7679 655.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"659.0001,-305.784 655.5,-295.784 652.0001,-305.784 659.0001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578707328416 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140578707328416</title>\n",
       "<polygon fill=\"none\" points=\"166,-166.5 166,-212.5 607,-212.5 607,-166.5 166,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-185.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"334,-166.5 334,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"334,-189.5 389,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"389,-166.5 389,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498\" y=\"-197.3\">[(None, 64), (None, 32), (None, 50)]</text>\n",
       "<polyline fill=\"none\" points=\"389,-189.5 607,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498\" y=\"-174.3\">(None, 146)</text>\n",
       "</g>\n",
       "<!-- 140578676749704&#45;&gt;140578707328416 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140578676749704-&gt;140578707328416</title>\n",
       "<path d=\"M413.4838,-498.418C408.4483,-440.7699 395.3043,-290.2943 389.421,-222.9402\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"392.8984,-222.5284 388.5414,-212.8709 385.925,-223.1376 392.8984,-222.5284\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676586984&#45;&gt;140578707328416 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140578676586984-&gt;140578707328416</title>\n",
       "<path d=\"M261.6901,-249.3799C282.5983,-239.3488 307.2486,-227.5224 329.096,-217.0406\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"330.7665,-220.1212 338.2685,-212.6399 327.7385,-213.81 330.7665,-220.1212\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676749368&#45;&gt;140578707328416 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140578676749368-&gt;140578707328416</title>\n",
       "<path d=\"M580.9257,-249.4901C546.8159,-238.9655 506.2425,-226.4466 471.0064,-215.5745\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"471.8068,-212.1587 461.2193,-212.5547 469.7429,-218.8475 471.8068,-212.1587\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578676587768 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140578676587768</title>\n",
       "<polygon fill=\"none\" points=\"255,-83.5 255,-129.5 518,-129.5 518,-83.5 255,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-102.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"380,-83.5 380,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"407.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"380,-106.5 435,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"407.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"435,-83.5 435,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-114.3\">(None, 146)</text>\n",
       "<polyline fill=\"none\" points=\"435,-106.5 518,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476.5\" y=\"-91.3\">(None, 146)</text>\n",
       "</g>\n",
       "<!-- 140578707328416&#45;&gt;140578676587768 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140578707328416-&gt;140578676587768</title>\n",
       "<path d=\"M386.5,-166.3799C386.5,-158.1745 386.5,-148.7679 386.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"390.0001,-139.784 386.5,-129.784 383.0001,-139.784 390.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140578707327912 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140578707327912</title>\n",
       "<polygon fill=\"none\" points=\"266.5,-.5 266.5,-46.5 506.5,-46.5 506.5,-.5 266.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-19.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"368.5,-.5 368.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"368.5,-23.5 423.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"423.5,-.5 423.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"465\" y=\"-31.3\">(None, 146)</text>\n",
       "<polyline fill=\"none\" points=\"423.5,-23.5 506.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"465\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140578676587768&#45;&gt;140578707327912 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140578676587768-&gt;140578707327912</title>\n",
       "<path d=\"M386.5,-83.3799C386.5,-75.1745 386.5,-65.7679 386.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"390.0001,-56.784 386.5,-46.784 383.0001,-56.784 390.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def plot_model_in_notebook(model):\n",
    "    return SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "plot_model_in_notebook(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a big model\n",
    "### If you can fit it on your computer (probably needs 16GB RAM) then do so\n",
    "### if not, try one epoch with a very small batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~2 min epoch\n",
    "model.fit(\n",
    "    [int_sequences_train, ft_sequences_train],\n",
    "    y_train, \n",
    "    epochs=1, \n",
    "    batch_size=128, \n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pd.DataFrame(model.history.history)[['acc', 'val_acc']].plot(\n",
    "    figsize=(16,9), fontsize=16, style='o', markersize=16\n",
    ")\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('epoch', fontsize=16)\n",
    "\n",
    "\n",
    "preds = (model.predict([\n",
    "    int_sequences_test, \n",
    "    ft_sequences_test\n",
    "]) > 0.5).squeeze().astype(int)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "plt.title('test accuracy = {:.3f}'.format(test_acc), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The crux of the problem!\n",
    "## Part 6: Why is this worse than combining by hand? \n",
    "### Please put plain text answers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: NER, again! (35%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, Dense\n",
    "from keras.initializers import Constant\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = '' # FIXME\n",
    "DATA_DIR = ''  # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_file(filepath):\n",
    "    word_to_vector = {}\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_to_vector[word] = vector\n",
    "    return word_to_vector\n",
    "\n",
    "def load_dataset(fname):\n",
    "    docs = []\n",
    "    with open(fname) as fd:\n",
    "        cur = []\n",
    "        for line in fd:\n",
    "            # new sentence on -DOCSTART- or blank line\n",
    "            if re.match(r\"-DOCSTART-.+\", line) or (len(line.strip()) == 0):\n",
    "                if len(cur) > 0:\n",
    "                    docs.append(cur)\n",
    "                cur = []\n",
    "            else: # read in tokens\n",
    "                cur.append(line.strip().split(\"\\t\",1))\n",
    "        # flush running buffer\n",
    "        if cur:\n",
    "            docs.append(cur)\n",
    "    return docs\n",
    "\n",
    "word_vecs = load_glove_file(GLOVE_FILE)\n",
    "docs = load_dataset(os.path.join(DATA_PATH, 'train.conll'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EU', 'ORG'],\n",
       " ['rejects', 'O'],\n",
       " ['German', 'MISC'],\n",
       " ['call', 'O'],\n",
       " ['to', 'O'],\n",
       " ['boycott', 'O'],\n",
       " ['British', 'MISC'],\n",
       " ['lamb', 'O'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_first_doc = [\n",
    "    ['EU', 'ORG'],\n",
    "    ['rejects', 'O'],\n",
    "    ['German', 'MISC'],\n",
    "    ['call', 'O'],\n",
    "    ['to', 'O'],\n",
    "    ['boycott', 'O'],\n",
    "    ['British', 'MISC'],\n",
    "    ['lamb', 'O'],\n",
    "    ['.', 'O']\n",
    "]\n",
    "\n",
    "assert len(word_vecs) == 400000, 'word vectors did not load properly'\n",
    "assert word_vecs['the'].shape == (50,), 'word vectors did not load properly'\n",
    "assert len(docs) == 14041, 'something has gone wrong with data loading'\n",
    "assert docs[0] == correct_first_doc, 'something has gone wrong with data loading'\n",
    "\n",
    "\n",
    "MAX_WORDS = len(word_vecs)  # max number of words to use in the embedding\n",
    "UNKNOWN = 'UUUNKKK'  # token for unknown word\n",
    "UNKNOWN_WORD_INDEX = 0\n",
    "EMBEDDING_DIM = 50  # dimension of embedding\n",
    "NULL_TAG = 'O'  # tags that are not a named entity\n",
    "\n",
    "# Some derived quantities\n",
    "TAGS = (NULL_TAG, 'LOC', 'PER', 'ORG', 'MISC')\n",
    "NUM_TO_TAG = {num + 1: tag for num, tag in enumerate(TAGS)}\n",
    "TAG_TO_NUM = {tag: num for num, tag in NUM_TO_TAG.items()}\n",
    "\n",
    "NUM_CLASSES = len(TAG_TO_NUM) + 1  # for padding\n",
    "assert NUM_CLASSES == 6, 'somethig has gone wrong'\n",
    "\n",
    "word_to_num = {word: idx + 1 for idx, word in enumerate(word_vecs.keys())}\n",
    "num_to_word = {num: word for word, num in word_to_num.items()}\n",
    "\n",
    "word_to_num[UNKNOWN] = UNKNOWN_WORD_INDEX\n",
    "num_to_word[UNKNOWN_WORD_INDEX] = UNKNOWN\n",
    "\n",
    "assert word_to_num['the'] < 10, '\"the\" is not a common word- something has gone wrong.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((MAX_WORDS, EMBEDDING_DIM))\n",
    "for word, i in word_to_num.items():#tok.word_index.items():\n",
    "    if i >= MAX_WORDS:\n",
    "        continue\n",
    "    embedding_vector = word_vecs.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_sequences(doc, word_to_num, tag_to_num):\n",
    "    \"\"\"Process a sequence\n",
    "    Args:\n",
    "        doc: a sequence of word, tag  (both are str)\n",
    "        word_to_num: a dictionary mapping a word to an integer\n",
    "        tag_to_num: a dictionary mapping a tag to an integer\n",
    "    \"\"\"\n",
    "    int_seq = []\n",
    "    tags = []\n",
    "    # TODO loop through doc and assembed `int_seq`, and `tags`\n",
    "    #     both of which should be integers instead of strings\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return int_seq, tags\n",
    "\n",
    "int_sequences = []\n",
    "tag_seqs = []\n",
    "\n",
    "# TODO\n",
    "# loop through docs\n",
    "# if the length of the document is less than 2, ignore it\n",
    "# otherwise process it into an integer sequence of words and\n",
    "# an integer sequences of tags (targets)\n",
    "# append the result to int_sequences and tag_seqs\n",
    "for doc in docs:\n",
    "    if len(doc) < 2:\n",
    "        continue\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert max(map(len, int_sequences)) == 113, 'something has gone wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# TODO:\n",
    "# 1. padd the integer sequences of words\n",
    "# 2. to the same with the tags (targets)\n",
    "# 3. Turn the tags into categorical variables\n",
    "\n",
    "\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13862, 115)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (\n",
    "    SimpleRNN, Dense, LSTM,\n",
    "    Embedding, Input, Dropout,\n",
    ")\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "#TODO: Build a netowrk\n",
    "# 1. make an input\n",
    "# 2. make a non-trainable embedding\n",
    "# 3. make a single, LSTM, add dropout and recurrent dropout\n",
    "# 4. Make a single dense hidden layer\n",
    "# 5. Make the correct-sized output layer\n",
    "#       the output should be softmax\n",
    "\n",
    "# make a model and compile it\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 328.00 387.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 324,-383 324,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140485476500592 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140485476500592</title>\n",
       "<polygon fill=\"none\" points=\"28.5,-332.5 28.5,-378.5 291.5,-378.5 291.5,-332.5 28.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91\" y=\"-351.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"153.5,-332.5 153.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"153.5,-355.5 208.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"208.5,-332.5 208.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-363.3\">(None, 115)</text>\n",
       "<polyline fill=\"none\" points=\"208.5,-355.5 291.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-340.3\">(None, 115)</text>\n",
       "</g>\n",
       "<!-- 140485476500536 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140485476500536</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 320,-295.5 320,-249.5 0,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-268.8\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-249.5 161,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-272.5 216,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-249.5 216,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-280.3\">(None, 115)</text>\n",
       "<polyline fill=\"none\" points=\"216,-272.5 320,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-257.3\">(None, 115, 50)</text>\n",
       "</g>\n",
       "<!-- 140485476500592&#45;&gt;140485476500536 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140485476500592-&gt;140485476500536</title>\n",
       "<path d=\"M160,-332.3799C160,-324.1745 160,-314.7679 160,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.5001,-305.784 160,-295.784 156.5001,-305.784 163.5001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140485476500480 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140485476500480</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-166.5 31.5,-212.5 288.5,-212.5 288.5,-166.5 31.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-185.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-166.5 129.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-189.5 184.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-166.5 184.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-197.3\">(None, 115, 50)</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-189.5 288.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-174.3\">(None, 115, 64)</text>\n",
       "</g>\n",
       "<!-- 140485476500536&#45;&gt;140485476500480 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140485476500536-&gt;140485476500480</title>\n",
       "<path d=\"M160,-249.3799C160,-241.1745 160,-231.7679 160,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.5001,-222.784 160,-212.784 156.5001,-222.784 163.5001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140485477169192 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140485477169192</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-83.5 29.5,-129.5 290.5,-129.5 290.5,-83.5 29.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-102.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-83.5 131.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-106.5 186.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-83.5 186.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-114.3\">(None, 115, 64)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-106.5 290.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-91.3\">(None, 115, 32)</text>\n",
       "</g>\n",
       "<!-- 140485476500480&#45;&gt;140485477169192 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140485476500480-&gt;140485477169192</title>\n",
       "<path d=\"M160,-166.3799C160,-158.1745 160,-148.7679 160,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.5001,-139.784 160,-129.784 156.5001,-139.784 163.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140485476834496 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140485476834496</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-.5 29.5,-46.5 290.5,-46.5 290.5,-.5 29.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-19.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-.5 131.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-23.5 186.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-.5 186.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-31.3\">(None, 115, 32)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-23.5 290.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-8.3\">(None, 115, 6)</text>\n",
       "</g>\n",
       "<!-- 140485477169192&#45;&gt;140485476834496 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140485477169192-&gt;140485476834496</title>\n",
       "<path d=\"M160,-83.3799C160,-75.1745 160,-65.7679 160,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.5001,-56.784 160,-46.784 156.5001,-56.784 163.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def plot_model_in_notebook(model):\n",
    "    return SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "plot_model_in_notebook(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    int_sequences, tag_seqs, \n",
    "    validation_split=0.2, \n",
    "    epochs=10, \n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today: None\n",
      "people: O\n",
      "will: O\n",
      "vote: O\n",
      "for: O\n",
      "president: O\n",
      "in: O\n",
      "Fooland: LOC\n",
      ",: O\n",
      "Janet: PER\n",
      "said: O\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "#sentence = 'I live in Brussels , BG.'.split()\n",
    "sentence = 'Today people will vote for president in Fooland , Janet said .'.split()\n",
    "\n",
    "# TODO:\n",
    "# 1. turn sentence (list of str) into an integer sequence\n",
    "# 2. Use the model, call `predict` on the integer sequence\n",
    "# 3. create a list of predicted labels for each word called `predicted_labels`\n",
    "# 4. remove the padding from predicted_labels\n",
    "\n",
    "#sent_int ...= [  # to be remove\n",
    "\n",
    "#preds = ...\n",
    "\n",
    "# predicted_labels = ... \n",
    "for word, lab in zip(sentence, predicted_labels):\n",
    "    print('{}: {}'.format(word, lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
